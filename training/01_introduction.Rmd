# Introduction to open science

These materials are meant to introduce you to the principles of open science, effective data management, and data archival with the DataONE data repository.

## Background reading

Read the content on the Arctic Data Center (ADC) webpage to learn more about data submission, preservation, and the history of the ADC. We encourage you to follow the links within these pages to gain a deeper understanding.

* <a href = 'https://arcticdata.io/about/' target='_blank'>about</a>
* <a href = 'https://arcticdata.io/submit/' target='_blank'>submission</a>
* <a href = 'https://arcticdata.io/preservation/' target='_blank'>preservation</a>
* <a href = 'https://arcticdata.io/history/' target='_blank'>history</a>

## Effective data management

Read Matt Jones et al.'s paper on <a href = 'data/simple-guidelines-datamgmt.pdf' target='_blank'>effective data management</a> to learn how we will be organizing datasets prior to archival.

(Please note that while the tips outlined in this article are best practices, we often do not reformat data files submitted to our repositories unless necessary. It is best to be conservative and not alter other people's data without good reason.)

You may also want to explore the DataONE <a href='https://www.dataone.org/Education' target='_blank'>education resources</a> related to data management.

## Using DataONE

**Data Observation Network for Earth** (DataONE) is a community driven initiative that provides access to data across multiple member repositories, supporting enhanced search and discovery of Earth and environmental data.

Read more about what DataONE is <a href = 'https://www.dataone.org/what-dataone' target='_blank'>here</a> and about DataONE member node (MN) guidelines <a href = 'https://www.dataone.org/sites/all/documents/DataONE_MN_Partner_Guidelines_20170501.pdf' target='_blank'>here</a>. Please feel free to ask Dom or Jesse any questions you have about DataONE.

## Working on a remote server

All of the work that we do at NCEAS is done on our remote server, datateam.nceas.ucsb.edu. If you have never worked on a remote server before, you can think of it like working on a different computer via the internet. 

We access RStudio on our server through this <a href = 'https://datateam.nceas.ucsb.edu/rstudio/' target='_blank'>link.</a> To transfer files on and off of the server we often use a secure FTP client, Cyberduck.

```{r, child = '../workflows/miscellaneous/cyberduck_instructions.Rmd'}
```

## A note on paths

On the servers, paths to files in your folder always start with `/home/yourusername/...`.

When you write scripts, try to avoid writing relative paths (which rely on what you have set your working directory to) as much as possible. Instead, write out the entire path as shown above, so that if another data team member needs to run your script, it is not dependent on a working directory.

## A note on R

This training assumes basic knowledge of R and RStudio. If you want a quick R refresher, walk through Jenny Bryan's excellent materials [here](http://stat545.com/block002_hello-r-workspace-wd-project.html).

Throughout this training we will occasionally use the namespace syntax `package_name::function_name()` when writing a function. This syntax denotes which package a function came from.  For example `dataone::getSystemMetadata` selects the `getSystemMetadata` function from the `dataone` R package. More detailed information on namespaces can be found [here](http://r-pkgs.had.co.nz/namespace.html).

## Exercise 1 {.exercise}

### Part 1
If you are comfortable programming in R please complete this section of the exercise.  If not please read through some of Jenny Bryan's materials [here](http://stat545.com/block002_hello-r-workspace-wd-project.html) (at least up to section 2.1), and then complete part 1 using excel or a different text editor of your choice. 
* Download the [csv](data/Loranty_2016_Environ._Res._Lett._11_095008.csv) of Table 1 from <a href = 'http://iopscience.iop.org/article/10.1088/1748-9326/11/9/095008/meta' target='_blank'>this paper.</a>
* Reformat the table to meet the guidelines outlined in the journal article on effective data management.
    + While we prefer you use R (a scripted environment) to perform these tasks in your job, for the purposes of this training feel free to do it however you can if you are not confident data wrangling in R.
    + If you need an R refresher, go over the <a href = 'http://www.datacarpentry.org/R-ecology-lesson/01-intro-to-r.html' target='_blank'>data carpentry guide.</a>
    + You may also find the data carpentry <a href = 'http://www.datacarpentry.org/R-ecology-lesson/03-dplyr.html' target='_blank'>lesson on `dplyr`</a> and OHI's <a href = 'http://ohi-science.org/data-science-training/dplyr.html' target='_blank'>data wrangling chapters</a> helpful.
    
### Part 2
* Go to "<a href = 'https://test.arcticdata.io/#data' target='_blank'>test.arcticdata.io</a>" and submit your reformatted file with appropriate metadata that you derive from the text of the paper:
    + list yourself as the first 'Creator' so your test submission can easily be found,
    + for the purposes of this training exercise, not every single author needs to be listed with full contact details, listing the first two authors is fine,
    + directly copying and pasting sections from the paper (abstract, methods, etc.) is also fine,
    + attributes (column names) should be defined, including correct units and missing value codes.

## Final checklist before notifying submitter

Before checking the data package manually, click on the "Quality report" button in the upper right corner of the landing page to review those automated checks for any potential issues, and remedy them as necessary.

Also, be sure to run `datamgmt::qa_package()` and then to correct all applicable issues the function returns.

Next, run through the manual checklist below. Once all these checks are satisfied, share the package for peer review in Slack #datateam prior to publication.

- **Descriptive title:** what, where, when - provides enough information to understand the contents at a general scientific level (please use sentence case so that only the first word and proper nouns are capitalized, as in a journal article title; do not add a period at the end, it will auto-populate). Be sure to fully spell out all terms and avoid abbreviations, initialisms, or acronyms unless they are only generally known as such.
    - Ex: "Active layer soil bulk density, moisture, carbon and nitrogen concentrations, and stable isotope data from borehole sites, Toolik Lake Field Station, Alaska, 2015"

- **Descriptive abstract:** specifies purpose, data collected, and other applicable information (&#8805;100 words) - provides an overview of the scientific context/project/hypotheses, how the data set fits into the larger project, a synopsis of the experimental or sampling design, and a summary of the data contents. Lean towards defining all abbreviations, initialisms, or acronyms unless they are only generally known as such.

    Bad example:

      - A low-resolution 3D model of a subglacial conduit derived from a photographic survey and structure-from-motion.

    Good example:

      - In this study, the locations of 193 old aerial photographs of northern Alaskan landscapes were re-photographed and assessed for changes in vegetation. The original photographs were taken over northern Alaska between 1948 and 1951, and the new photographs were taken between 1999 and 2003. The region covered by the original and repeat photographs stretches from the southern extent of the Brooks Range in the south to the Coastal Plain in the north, and from the Chukchi Sea in the west to the Canning River in the east. The original photographs were taken by the U.S. military as part of geologic reconnaissance and exploration, and the method used to acquire them was to fly both sides of a river valley while photographing the river and the facing valley slopes. Of the several thousand original photographs, only a fraction were repeated for the purpose of assessing vegetation change. Repeat photographs were selected for geographic coverage and to produce the greatest likelihood of detecting vegetation change. The original and repeat photographs were then scanned and stored in TIFF format. Individual image file sizes range from 5 to 60 MB each, and the total file size for the data set is approximately 11 GB.

- **Keywords** some keywords are included

- **Publication Date** is included (the EML has a `pubDate` that is at least the current four-digit year)

- **Data file types** are registered DataONE formats and properly set in the EML (`formatName`) and the system metadata for ALL DATA OBJECTS
    - See registered DataOne formats [here](https://cn.dataone.org/cn/v2/formats)
    - Data files stored using proprietary software could disappear or no longer be accessible when the software is no longer available. Preserving data in text-based, open-source file formats ensures preservation of data for, theoretically, all time (ex: CSV instead of XLS). These transferable file formats also reduce the possibility of information being "lost in translation".

- `fileName` is properly set (including extension) in the system metadata for all objects (besides resource map) - do this by using `set_file_name()`

- **Data file names:** clear, but short descriptions without blank spaces (include extension)
- Ex: “Corvallis_VegBiodiv_2007.csv”

- **Column headers** (within data files): no spaces (use underscore or camelCase), `attributeList` adequately defines ALL column headers (including units)

- **Cell etiquette:** only one value (piece of information) per cell (for lat/long use decimal degrees) - `attributeList` should define ALL codes used (including defining missing value codes; WHY are data absent?)

- **Entity level metadata:**     
- Each data file has either a `dataTable` or an `otherEntity`

- `entityName`s are properly set in all `dataTable`s and `otherEntity`s

- `entityDescription`s are set in all `dataTable`s and `otherEntity`s

- Download buttons in `dataTable`s and `otherEntity`s download correct data files

- `dataTable`s and `otherEntity`s must include `physical` - all `physical` sections match the information for the respective data object: `objectName` (including extension), `size` (including units), `authentication` (checksum), `formatName` (file format), and `url` (online distribution info links end in correct PID)

- Any `dimensionless` units entered through the editor must be checked and quality controlled for accuracy. For attributes with `numericDomain`s, the editor has a unit option of "Other / None" which populates as `dimensionless` in the EML. There is also a `dimensionless` option for submitters. While some attributes may be correctly marked as `dimensionless` (percent, ppm, ppb, other ratios, etc.), others may just be a placeholder in need of a custom unit. Please refer to [here](https://nceas.github.io/datateam-training/reference/assess-attributes.html) for more information.

- **Creator and contact roles** are complete
      - First/Last Name, emails are essential - use ONE `givenName` slot for EACH first OR middle name, like so:  
      `<individualName>  
        <givenName>Austin</givenName>  
        <givenName>Samuel</givenName>  
        <surName>Post</surName>  
      </individualName>`  
      - Whenever they exist and are known, ORCID iDs should be included for all party types - enter iDs (in this format:  
      `<userId directory="https://orcid.org/">https://orcid.org/0000-0000-0000-0000</userId>`)  
      in the `userId` slots. Note the "s" in "https". See how to do this in an automated fashion [here](https://nceas.github.io/datateam-training/training/edit-eml-in-r.html#edit-an-eml-element)  
      - Use the `references` tag to copy information for the same individual to multiple party types (`creator`, `contact`, `associatedParty`), [like so](https://nceas.github.io/datateam-training/reference/use-references.html)  
      - Emails are important, phone #s and addresses are less critical

- **Geographic and temporal ranges** are sensible (start date precedes end date) and appropriate to the study site and period; geographic description is accurate and includes commonly understood context

    Bad examples:

      - "Svalbard"
      - "Sag River"

    Good examples:

      - "Svalbard, Norway"
      - "Sagavanirktok River, North Slope, Alaska"

- **Funding numbers** are accurate and included
    - NSF-funded projects can be searched [here](https://www.nsf.gov/awardsearch/); we also accept non-NSF funded arctic data sets

- **Methods:** provide enough detail so that a reasonable scientist can interpret the study and data for reuse without needing to consult anyone nor any other resources

- Ensure that the `project` section of the EML matches the information from the NSF award as opposed to only being specific to this one data package

- Double check for garbled symbols, spelling, and grammatical errors

- Mention parent or childs when key EML fields are otherwise left empty. (e.g.: If an abstract or methods section is absent or very terse because these sections are robust and sufficient on a different level of nesting, be sure to explicitly mention that in the sparse EML's appropriate section so users know where to look.)

- If the data set is still private and awaiting PI and/or submitter review, be sure that the `accessPolicy`s on ALL OBJECTS (metadata, resource map, data objects) grants `read`, `write`, and `changePermission` privileges to the PI's and/or submitter's ORCID iDs (in this format: "http://orcid.org/XXXX-XXXX-XXXX-XXXX") - do this using `set_access()`. **Make sure to OMIT the "s" after "http" in the ORCiD for this sysmeta field. This is different than how we want ORCiDs formatted in EMLs**

- `rightsHolder` is properly set (in this format: "http://orcid.org/XXXX-XXXX-XXXX-XXXX") to PIs on ALL OBJECTS (metadata, resource map, data objects) - do this using `set_rights_holder()` - **this should be one of the last steps**

- Add back in any provenance relationships **after** publishing with a DOI - they may have gotten wiped by your last update

- Ensure that the https://doi.org/10.18739/XXXXXXXXX redirect works before emailing the Requestor with that URL. Occasionally, it takes almost 24 hours, but usually it only takes from 1 to 30 minutes. If the redirect does not happen, tell Jesse. If you assigned an SID, tell Jesse right away as he likely needs to manually set up the redirect.
